{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Processing each document independently...\n",
      "============================================================\n",
      "\n",
      "✓ elon_musk_4_transcript_clean.jsonl:\n",
      "  → Loaded 566 raw blocks\n",
      "  → Merged to 523 blocks\n",
      "  → Created 261 pairs from elon_musk_4_transcript_clean.jsonl\n",
      "\n",
      "✓ joe-rogan-experience-1169-elon-musk.csv:\n",
      "  → Loaded 1831 raw blocks\n",
      "  → Merged to 1792 blocks\n",
      "  → Created 881 pairs from joe-rogan-experience-1169-elon-musk.csv\n",
      "\n",
      "✓ output.jsonl:\n",
      "  → Loaded 592 raw blocks\n",
      "  → Merged to 551 blocks\n",
      "  → Created 267 pairs from output.jsonl\n",
      "\n",
      "✓ QR_Pairs (2).jsonl:\n",
      "  → Loaded 164 raw blocks\n",
      "  → Merged to 164 blocks\n",
      "  → Created 82 pairs from QR_Pairs (2).jsonl\n",
      "\n",
      "✓ ElonVCpodcast2010.jsonl:\n",
      "  → Loaded 42 raw blocks\n",
      "  → Merged to 42 blocks\n",
      "  → Created 21 pairs from ElonVCpodcast2010.jsonl\n",
      "\n",
      "✓ Elon_Trump_Transcript.json:\n",
      "  → Loaded 373 raw blocks\n",
      "  → Merged to 370 blocks\n",
      "  → Created 185 pairs from Elon_Trump_Transcript.json\n",
      "\n",
      "✓ Elon Musk With Lara Trump (FULL INTERVIEW).txt:\n",
      "  → Loaded 60 raw blocks\n",
      "  → Merged to 60 blocks\n",
      "  → Created 30 pairs from Elon Musk With Lara Trump (FULL INTERVIEW).txt\n",
      "\n",
      "✓ Elon Musk on Racism, Bailing Out Trump, Hate Speech, and More - The Don Lemon Show (Full Interview) [hhsfjBpKiTw].txt:\n",
      "  → Loaded 349 raw blocks\n",
      "  → Merged to 349 blocks\n",
      "  → Created 174 pairs from Elon Musk on Racism, Bailing Out Trump, Hate Speech, and More - The Don Lemon Show (Full Interview) [hhsfjBpKiTw].txt\n",
      "\n",
      "✓ Elon Musk_ “10X Every 6 Months” [FPpPTp7FIHY].txt:\n",
      "  → Loaded 98 raw blocks\n",
      "  → Merged to 98 blocks\n",
      "  → Created 49 pairs from Elon Musk_ “10X Every 6 Months” [FPpPTp7FIHY].txt\n",
      "\n",
      "✓ Full Elon Musk Interview at CPAC 2025 _ Unfiltered, Unscripted, Unmissable [L2hkqolW168].txt:\n",
      "  → Loaded 173 raw blocks\n",
      "  → Merged to 173 blocks\n",
      "  → Created 86 pairs from Full Elon Musk Interview at CPAC 2025 _ Unfiltered, Unscripted, Unmissable [L2hkqolW168].txt\n",
      "\n",
      "✓ Elon Musk & Ben Shapiro in Passionate Interview [JGdbFGANapk].txt:\n",
      "  → Loaded 71 raw blocks\n",
      "  → Merged to 71 blocks\n",
      "  → Created 35 pairs from Elon Musk & Ben Shapiro in Passionate Interview [JGdbFGANapk].txt\n",
      "\n",
      "✓ Elon Musk Interview _ The Future, Engineered _ X Takeover 2025 [YqDehngsBHw].txt:\n",
      "  → Loaded 94 raw blocks\n",
      "  → Merged to 94 blocks\n",
      "  → Created 47 pairs from Elon Musk Interview _ The Future, Engineered _ X Takeover 2025 [YqDehngsBHw].txt\n",
      "\n",
      "✓ Elon Musk on DOGE, Optimus, Starlink Smartphones, Evolving with AI, Why the West is Imploding [qeZqZBRA-6Q].txt:\n",
      "  → Loaded 108 raw blocks\n",
      "  → Merged to 89 blocks\n",
      "  → Created 44 pairs from Elon Musk on DOGE, Optimus, Starlink Smartphones, Evolving with AI, Why the West is Imploding [qeZqZBRA-6Q].txt\n",
      "\n",
      "✓ Elon Musk Talks Tesla, Politics and Putin Relationship (Full Interview) [gPGZRJDVXcU].txt:\n",
      "  → Loaded 113 raw blocks\n",
      "  → Merged to 113 blocks\n",
      "  → Created 56 pairs from Elon Musk Talks Tesla, Politics and Putin Relationship (Full Interview) [gPGZRJDVXcU].txt\n",
      "\n",
      "✓ ELON UNCUT - THE COMPLETE INTERVIEW _ Verdict Ep. 216 [aMcmuKTfr54].txt:\n",
      "  → Loaded 342 raw blocks\n",
      "  → Merged to 315 blocks\n",
      "  → Created 157 pairs from ELON UNCUT - THE COMPLETE INTERVIEW _ Verdict Ep. 216 [aMcmuKTfr54].txt\n",
      "\n",
      "✓ Elon Musk introducing Grok 4 (FULL VIDEO) [QbNODZwQQuw].txt:\n",
      "  → Loaded 97 raw blocks\n",
      "  → Merged to 69 blocks\n",
      "  → Created 35 pairs from Elon Musk introducing Grok 4 (FULL VIDEO) [QbNODZwQQuw].txt\n",
      "\n",
      "✓ Elon Musk Interview With Ben Shapiro (FULL INTERVIEW) [S_vpv4I27hs].txt:\n",
      "  → Loaded 113 raw blocks\n",
      "  → Merged to 113 blocks\n",
      "  → Created 57 pairs from Elon Musk Interview With Ben Shapiro (FULL INTERVIEW) [S_vpv4I27hs].txt\n",
      "\n",
      "✓ Elon Musk talks Twitter, Tesla and how his brain works — live at TED2022 [cdZZpaB2kDM].txt:\n",
      "  → Loaded 138 raw blocks\n",
      "  → Merged to 138 blocks\n",
      "  → Created 69 pairs from Elon Musk talks Twitter, Tesla and how his brain works — live at TED2022 [cdZZpaB2kDM].txt\n",
      "\n",
      "✓ Rishi Sunak & Elon Musk_ Talk AI, Tech & the Future [R2meHtrO1n8].txt:\n",
      "  → Loaded 76 raw blocks\n",
      "  → Merged to 76 blocks\n",
      "  → Created 38 pairs from Rishi Sunak & Elon Musk_ Talk AI, Tech & the Future [R2meHtrO1n8].txt\n",
      "\n",
      "✓ Elon Musk_ Digital Superintelligence, Multiplanetary Life, How to Be Useful [cFIlta1GkiE].txt:\n",
      "  → Loaded 65 raw blocks\n",
      "  → Merged to 65 blocks\n",
      "  → Created 32 pairs from Elon Musk_ Digital Superintelligence, Multiplanetary Life, How to Be Useful [cFIlta1GkiE].txt\n",
      "\n",
      "✓ Trump, Musk pull curtain back behind relationship, media's divide and conquer mission [hMbcMO5JgEo].txt:\n",
      "  → Loaded 110 raw blocks\n",
      "  → Merged to 68 blocks\n",
      "  → Created 34 pairs from Trump, Musk pull curtain back behind relationship, media's divide and conquer mission [hMbcMO5JgEo].txt\n",
      "\n",
      "✓ Musk and Trump explain why it's essential to cut funding, 'weed out corruption' [BN6xgxRNZeI].txt:\n",
      "  → Loaded 45 raw blocks\n",
      "  → Merged to 39 blocks\n",
      "  → Created 19 pairs from Musk and Trump explain why it's essential to cut funding, 'weed out corruption' [BN6xgxRNZeI].txt\n",
      "\n",
      "✓ tucker_carlson.txt:\n",
      "  → Loaded 448 raw blocks\n",
      "  → Merged to 448 blocks\n",
      "  → Created 224 pairs from tucker_carlson.txt\n",
      "\n",
      "============================================================\n",
      "Applying identity injection (30% rate)...\n",
      "============================================================\n",
      "✓ Applied to 833/2883 pairs\n",
      "\n",
      "============================================================\n",
      "Dataset Summary\n",
      "============================================================\n",
      "Total training pairs: 2883\n",
      "System message: 'You are Elon Musk.'\n",
      "Identity injection rate: 30%\n",
      "Context window: up to 10 previous turns\n",
      "✓ Saved to: instruction_response_context22.json\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Sample Training Pair\n",
      "============================================================\n",
      "Context turns: 1\n",
      "Response length: 19 chars\n",
      "\n",
      "Full sample:\n",
      "{\n",
      "  \"instruction\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are Elon Musk.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"The following is a conversation with Elon Musk, his fourth time on this, the Lex Fridman Podcast. I thought you were going to finish it. It\\u2019s one of the greatest themes in all of film history.\"\n",
      "    }\n",
      "  ],\n",
      "  \"response\": \"Yeah, that\\u2019s great.\"\n",
      "}...\n"
     ]
    }
   ],
   "source": [
    "# Identity cue injection - CORRECT: Each document processed independently\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "jsonl_file = \"elon_musk_4_transcript_clean.jsonl\"\n",
    "csv_file = \"joe-rogan-experience-1169-elon-musk.csv\"\n",
    "qa_jsonl_file = \"output.jsonl\"\n",
    "qr_pairs_file = \"QR_Pairs (2).jsonl\"\n",
    "elon_vc_podcast_file = \"ElonVCpodcast2010.jsonl\"\n",
    "elon_trump_file = \"Elon_Trump_Transcript.json\"\n",
    "lara_trump_file = \"Elon Musk With Lara Trump (FULL INTERVIEW).txt\"\n",
    "don_lemon_file = \"Elon Musk on Racism, Bailing Out Trump, Hate Speech, and More - The Don Lemon Show (Full Interview) [hhsfjBpKiTw].txt\"\n",
    "ten_x_file = \"Elon Musk_ “10X Every 6 Months” [FPpPTp7FIHY].txt\"\n",
    "cpac_file = \"Full Elon Musk Interview at CPAC 2025 _ Unfiltered, Unscripted, Unmissable [L2hkqolW168].txt\"\n",
    "ben_shapiro_file = \"Elon Musk & Ben Shapiro in Passionate Interview [JGdbFGANapk].txt\"\n",
    "x_takeover_file = \"Elon Musk Interview _ The Future, Engineered _ X Takeover 2025 [YqDehngsBHw].txt\"\n",
    "doge_optimus_file = \"Elon Musk on DOGE, Optimus, Starlink Smartphones, Evolving with AI, Why the West is Imploding [qeZqZBRA-6Q].txt\"\n",
    "tesla_politics_file = \"Elon Musk Talks Tesla, Politics and Putin Relationship (Full Interview) [gPGZRJDVXcU].txt\"\n",
    "verdict_file = \"ELON UNCUT - THE COMPLETE INTERVIEW _ Verdict Ep. 216 [aMcmuKTfr54].txt\"\n",
    "grok_4_file = \"Elon Musk introducing Grok 4 (FULL VIDEO) [QbNODZwQQuw].txt\"\n",
    "ben_shapiro_2_file = \"Elon Musk Interview With Ben Shapiro (FULL INTERVIEW) [S_vpv4I27hs].txt\"\n",
    "ted_2022_file = \"Elon Musk talks Twitter, Tesla and how his brain works — live at TED2022 [cdZZpaB2kDM].txt\"\n",
    "rishi_sunak_file = \"Rishi Sunak & Elon Musk_ Talk AI, Tech & the Future [R2meHtrO1n8].txt\"\n",
    "superintelligence_file = \"Elon Musk_ Digital Superintelligence, Multiplanetary Life, How to Be Useful [cFIlta1GkiE].txt\"\n",
    "trump_2_file = \"Trump, Musk pull curtain back behind relationship, media's divide and conquer mission [hMbcMO5JgEo].txt\"\n",
    "trump_doge_file = \"Musk and Trump explain why it's essential to cut funding, 'weed out corruption' [BN6xgxRNZeI].txt\"\n",
    "tucker_carlson_file = \"tucker_carlson.txt\"\n",
    "output_file = \"instruction_response_context22.json\"\n",
    "max_context_turns = 10\n",
    "response_speaker = \"elon musk\"\n",
    "identity_injection_rate = 0.30\n",
    "\n",
    "# ----------------------------\n",
    "# System message\n",
    "# ----------------------------\n",
    "identity_system_message = \"You are Elon Musk.\"\n",
    "\n",
    "# Conversation-specific system messages\n",
    "conversation_system_messages = {\n",
    "    \"trump\": \"You are Elon Musk in a conversation with Donald Trump.\",\n",
    "    \"trump_2\": \"You are Elon Musk in an interview with Donald Trump.\",\n",
    "    \"trump_doge\": \"You are Elon Musk in an interview with Donald Trump about the Department of Government Efficiency (DOGE).\",\n",
    "    \"lara_trump\": \"You are Elon Musk in an interview with Lara Trump.\",\n",
    "    \"joe_rogan\": identity_system_message,\n",
    "    \"don_lemon\": identity_system_message,\n",
    "    \"default\": identity_system_message\n",
    "}\n",
    "\n",
    "# Control what percentage of each conversation type gets enhanced context\n",
    "# This prevents large datasets from biasing the model toward one context\n",
    "context_injection_rates = {\n",
    "    \"trump\": 1.0,           # 100% - small dataset, needs all the help\n",
    "    \"trump_2\": 1.0,         # 100% - small dataset\n",
    "    \"trump_doge\": 1.0,      # 100% - small dataset\n",
    "    \"lara_trump\": 1.0,      # 100% - small dataset\n",
    "    \"don_lemon\": 1.0,       # 100% - small dataset\n",
    "    \"ten_x\": 1.0,           # 100% - small dataset\n",
    "    \"cpac\": 1.0,            # 100% - small dataset\n",
    "    \"ben_shapiro\": 1.0,     # 100% - small dataset\n",
    "    \"x_takeover\": 1.0,      # 100% - small dataset\n",
    "    \"doge_optimus\": 1.0,    # 100% - small dataset\n",
    "    \"tesla_politics\": 1.0,  # 100% - small dataset\n",
    "    \"verdict\": 1.0,         # 100% - small dataset\n",
    "    \"grok_4\": 1.0,          # 100% - small dataset\n",
    "    \"ben_shapiro_2\": 1.0,   # 100% - small dataset\n",
    "    \"ted_2022\": 1.0,        # 100% - small dataset\n",
    "    \"rishi_sunak\": 1.0,     # 100% - small dataset\n",
    "    \"superintelligence\": 1.0,  # 100% - small dataset\n",
    "    \"tucker_carlson\": 1.0,  # 100% - small dataset\n",
    "    \"joe_rogan\": 1.0,       # 30% - large dataset, don't over-emphasize\n",
    "    \"default\": 0.0          # 0% - keep general\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# Universal merging function\n",
    "# ----------------------------\n",
    "def merge_consecutive_speakers(blocks):\n",
    "    \"\"\"\n",
    "    Merge consecutive blocks from the same speaker within a conversation.\n",
    "    \"\"\"\n",
    "    if not blocks:\n",
    "        return []\n",
    "    \n",
    "    merged_blocks = []\n",
    "    current_speaker = None\n",
    "    current_text = \"\"\n",
    "    \n",
    "    for block in blocks:\n",
    "        speaker = block[\"speaker\"]\n",
    "        text = block[\"text\"]\n",
    "        \n",
    "        if speaker == current_speaker:\n",
    "            # Same speaker - merge text\n",
    "            current_text += \" \" + text\n",
    "        else:\n",
    "            # Different speaker - save previous block\n",
    "            if current_speaker is not None:\n",
    "                merged_blocks.append({\"speaker\": current_speaker, \"text\": current_text})\n",
    "            current_speaker = speaker\n",
    "            current_text = text\n",
    "    \n",
    "    # Don't forget the last block\n",
    "    if current_speaker is not None:\n",
    "        merged_blocks.append({\"speaker\": current_speaker, \"text\": current_text})\n",
    "    \n",
    "    return merged_blocks\n",
    "\n",
    "# ----------------------------\n",
    "# Create pairs from merged blocks\n",
    "# ----------------------------\n",
    "def create_pairs_from_blocks(blocks, source_name, conversation_type=\"default\"):\n",
    "    \"\"\"\n",
    "    Create instruction-response pairs from dialogue blocks.\n",
    "    Each pair includes context from previous turns in THIS conversation only.\n",
    "    \"\"\"\n",
    "    pairs = []\n",
    "    \n",
    "    # Get context injection rate for this conversation type\n",
    "    injection_rate = context_injection_rates.get(conversation_type, 0.0)\n",
    "    enhanced_system_message = conversation_system_messages.get(conversation_type, identity_system_message)\n",
    "    \n",
    "    for i in range(len(blocks)):\n",
    "        # Only create pairs where Elon is responding\n",
    "        if blocks[i][\"speaker\"].lower() != response_speaker.lower():\n",
    "            continue\n",
    "        \n",
    "        # Get context (previous conversation turns from THIS conversation)\n",
    "        # Start from up to max_context_turns back, or from beginning\n",
    "        start_idx = max(0, i - max_context_turns)\n",
    "        context_blocks = blocks[start_idx:i]\n",
    "        \n",
    "        # Decide whether to use enhanced or default system message\n",
    "        if random.random() < injection_rate:\n",
    "            system_message = enhanced_system_message\n",
    "        else:\n",
    "            system_message = identity_system_message\n",
    "        \n",
    "        # Build instruction with system message\n",
    "        instruction = [{\n",
    "            \"role\": \"system\",\n",
    "            \"content\": system_message\n",
    "        }]\n",
    "        \n",
    "        # Add conversation history (only previous turns, not current response)\n",
    "        for b in context_blocks:\n",
    "            role = \"assistant\" if b[\"speaker\"].lower() == response_speaker.lower() else \"user\"\n",
    "            instruction.append({\"role\": role, \"content\": b[\"text\"]})\n",
    "        \n",
    "        # Response is Elon's actual words\n",
    "        response = blocks[i][\"text\"]\n",
    "        \n",
    "        pairs.append({\"instruction\": instruction, \"response\": response})\n",
    "    \n",
    "    print(f\"  → Created {len(pairs)} pairs from {source_name}\")\n",
    "    return pairs\n",
    "\n",
    "# ----------------------------\n",
    "# Process single document\n",
    "# ----------------------------\n",
    "def process_document(raw_blocks, source_name, conversation_type=\"default\"):\n",
    "    \"\"\"\n",
    "    Process a single document/conversation:\n",
    "    1. Merge consecutive same-speaker turns\n",
    "    2. Create instruction-response pairs with context\n",
    "    \"\"\"\n",
    "    if not raw_blocks:\n",
    "        print(f\"✓ {source_name}: No data\")\n",
    "        return []\n",
    "    \n",
    "    print(f\"\\n✓ {source_name}:\")\n",
    "    print(f\"  → Loaded {len(raw_blocks)} raw blocks\")\n",
    "    \n",
    "    # Merge consecutive same-speaker turns\n",
    "    merged_blocks = merge_consecutive_speakers(raw_blocks)\n",
    "    print(f\"  → Merged to {len(merged_blocks)} blocks\")\n",
    "    \n",
    "    # Create pairs with context from this conversation only\n",
    "    pairs = create_pairs_from_blocks(merged_blocks, source_name, conversation_type)\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "# ----------------------------\n",
    "# Data loading functions\n",
    "# ----------------------------\n",
    "def load_jsonl_standard(file_path):\n",
    "    \"\"\"Load standard JSONL with 'speaker' and 'text' fields\"\"\"\n",
    "    blocks = []\n",
    "    if not os.path.exists(file_path):\n",
    "        return blocks\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                data = json.loads(line.strip())\n",
    "                blocks.append({\"speaker\": data[\"speaker\"], \"text\": data[\"text\"]})\n",
    "            except:\n",
    "                continue\n",
    "    return blocks\n",
    "\n",
    "def load_csv_standard(file_path):\n",
    "    \"\"\"Load CSV with Speaker and Text columns\"\"\"\n",
    "    blocks = []\n",
    "    if not os.path.exists(file_path):\n",
    "        return blocks\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            blocks.append({\"speaker\": row[\"Speaker\"], \"text\": row[\"Text\"]})\n",
    "    return blocks\n",
    "\n",
    "def load_qa_jsonl(file_path):\n",
    "    \"\"\"Load Q&A format JSONL (output.jsonl style)\"\"\"\n",
    "    blocks = []\n",
    "    if not os.path.exists(file_path):\n",
    "        return blocks\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                qa = json.loads(line.strip())\n",
    "                blocks.append({\n",
    "                    \"speaker\": qa.get(\"question_speaker\", \"interviewer\"),\n",
    "                    \"text\": qa[\"question\"]\n",
    "                })\n",
    "                blocks.append({\n",
    "                    \"speaker\": qa.get(\"response_speaker\", response_speaker),\n",
    "                    \"text\": qa[\"response\"]\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "    return blocks\n",
    "\n",
    "def load_qr_pairs(file_path):\n",
    "    \"\"\"Load QR_Pairs.jsonl format (Q and A fields)\"\"\"\n",
    "    blocks = []\n",
    "    if not os.path.exists(file_path):\n",
    "        return blocks\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                qr = json.loads(line.strip())\n",
    "                blocks.append({\n",
    "                    \"speaker\": \"interviewer\",\n",
    "                    \"text\": qr[\"Q\"]\n",
    "                })\n",
    "                blocks.append({\n",
    "                    \"speaker\": response_speaker,\n",
    "                    \"text\": qr[\"A\"]\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "    return blocks\n",
    "\n",
    "def load_elon_vc_podcast(file_path):\n",
    "    \"\"\"\n",
    "    Load ElonVCpodcast2010.jsonl format\n",
    "    speaker: 0 = Elon (assistant)\n",
    "    speaker: any other number = interviewer (user)\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    if not os.path.exists(file_path):\n",
    "        return blocks\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                entry = json.loads(line.strip())\n",
    "                \n",
    "                # Determine speaker\n",
    "                if entry[\"speaker\"] == 0:\n",
    "                    speaker_name = response_speaker\n",
    "                else:\n",
    "                    speaker_name = \"interviewer\"\n",
    "                \n",
    "                blocks.append({\n",
    "                    \"speaker\": speaker_name,\n",
    "                    \"text\": entry[\"transcript\"]\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Skipped malformed line: {e}\")\n",
    "                continue\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "def load_elon_trump_transcript(file_path):\n",
    "    \"\"\"\n",
    "    Load Elon_Trump_Transcript.json format\n",
    "    JSON array with 'speaker', 'timestamp', and 'text' fields\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    if not os.path.exists(file_path):\n",
    "        return blocks\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        try:\n",
    "            data = json.load(f)\n",
    "            for entry in data:\n",
    "                blocks.append({\n",
    "                    \"speaker\": entry[\"speaker\"],\n",
    "                    \"text\": entry[\"text\"]\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to load {file_path}: {e}\")\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "def load_speaker_transcript(file_path):\n",
    "    \"\"\"\n",
    "    Load plain text transcript with \"Speaker #:\" format\n",
    "    Speaker 0 = Elon Musk (assistant)\n",
    "    Speaker 1 = Interviewer (user)\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    if not os.path.exists(file_path):\n",
    "        return blocks\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Split by speaker pattern: \"Speaker #:\"\n",
    "    # Pattern matches \"Speaker\" followed by space, digit(s), colon\n",
    "    pattern = r'Speaker\\s+(\\d+):\\s*'\n",
    "    \n",
    "    # Split content and capture speaker numbers\n",
    "    parts = re.split(pattern, content)\n",
    "    \n",
    "    # parts[0] is empty or preamble, then alternates: speaker_num, text, speaker_num, text...\n",
    "    for i in range(1, len(parts), 2):\n",
    "        if i + 1 < len(parts):\n",
    "            speaker_num = int(parts[i])\n",
    "            text = parts[i + 1].strip()\n",
    "            \n",
    "            if not text:  # Skip empty utterances\n",
    "                continue\n",
    "            \n",
    "            # Map speaker number to role\n",
    "            if speaker_num == 0:\n",
    "                speaker_name = response_speaker\n",
    "            else:\n",
    "                speaker_name = \"interviewer\"\n",
    "            \n",
    "            blocks.append({\n",
    "                \"speaker\": speaker_name,\n",
    "                \"text\": text\n",
    "            })\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "def load_speaker_transcript_reversed(file_path):\n",
    "    \"\"\"\n",
    "    Load plain text transcript with \"Speaker #:\" format (REVERSED MAPPING)\n",
    "    Speaker 1 = Elon Musk (assistant)\n",
    "    Speaker 0 or any other number = Interviewer (user)\n",
    "    \"\"\"\n",
    "    blocks = []\n",
    "    if not os.path.exists(file_path):\n",
    "        return blocks\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    # Split by speaker pattern: \"Speaker #:\"\n",
    "    pattern = r'Speaker\\s+(\\d+):\\s*'\n",
    "    \n",
    "    # Split content and capture speaker numbers\n",
    "    parts = re.split(pattern, content)\n",
    "    \n",
    "    # parts[0] is empty or preamble, then alternates: speaker_num, text, speaker_num, text...\n",
    "    for i in range(1, len(parts), 2):\n",
    "        if i + 1 < len(parts):\n",
    "            speaker_num = int(parts[i])\n",
    "            text = parts[i + 1].strip()\n",
    "            \n",
    "            if not text:  # Skip empty utterances\n",
    "                continue\n",
    "            \n",
    "            # REVERSED: Speaker 1 is Elon, all others are interviewer\n",
    "            if speaker_num == 1:\n",
    "                speaker_name = response_speaker\n",
    "            else:\n",
    "                speaker_name = \"interviewer\"\n",
    "            \n",
    "            blocks.append({\n",
    "                \"speaker\": speaker_name,\n",
    "                \"text\": text\n",
    "            })\n",
    "    \n",
    "    return blocks\n",
    "\n",
    "# ----------------------------\n",
    "# Identity injection\n",
    "# ----------------------------\n",
    "def inject_identity_naturally(messages):\n",
    "    \"\"\"Minimal, natural identity injection\"\"\"\n",
    "    if not messages:\n",
    "        return messages\n",
    "    \n",
    "    messages = [{\"role\": msg[\"role\"], \"content\": msg[\"content\"]} for msg in messages]\n",
    "    \n",
    "    # Find first user message\n",
    "    user_indices = [i for i, msg in enumerate(messages) if msg[\"role\"] == \"user\"]\n",
    "    if not user_indices:\n",
    "        return messages\n",
    "    \n",
    "    # Very subtle - mostly no prefix\n",
    "    prefixes = [\"Elon, \", \"\", \"\", \"\", \"\"]\n",
    "    \n",
    "    # Only inject 40% of the time in first message\n",
    "    if random.random() < 0.4:\n",
    "        first_idx = user_indices[0]\n",
    "        prefix = random.choice(prefixes)\n",
    "        if prefix:\n",
    "            messages[first_idx][\"content\"] = f\"{prefix}{messages[first_idx]['content']}\".strip()\n",
    "    \n",
    "    return messages\n",
    "\n",
    "# ----------------------------\n",
    "# MAIN PROCESSING\n",
    "# ----------------------------\n",
    "print(\"=\" * 60)\n",
    "print(\"Processing each document independently...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_pairs = []\n",
    "\n",
    "# Document 1: Standard JSONL\n",
    "raw_blocks_1 = load_jsonl_standard(jsonl_file)\n",
    "pairs_1 = process_document(raw_blocks_1, jsonl_file)\n",
    "all_pairs.extend(pairs_1)\n",
    "\n",
    "# Document 2: CSV\n",
    "raw_blocks_2 = load_csv_standard(csv_file)\n",
    "pairs_2 = process_document(raw_blocks_2, csv_file, conversation_type=\"joe_rogan\")\n",
    "all_pairs.extend(pairs_2)\n",
    "\n",
    "# Document 3: Q&A JSONL\n",
    "raw_blocks_3 = load_qa_jsonl(qa_jsonl_file)\n",
    "pairs_3 = process_document(raw_blocks_3, qa_jsonl_file)\n",
    "all_pairs.extend(pairs_3)\n",
    "\n",
    "# Document 4: QR Pairs\n",
    "raw_blocks_4 = load_qr_pairs(qr_pairs_file)\n",
    "pairs_4 = process_document(raw_blocks_4, qr_pairs_file)\n",
    "all_pairs.extend(pairs_4)\n",
    "\n",
    "# Document 5: Elon VC Podcast\n",
    "raw_blocks_5 = load_elon_vc_podcast(elon_vc_podcast_file)\n",
    "pairs_5 = process_document(raw_blocks_5, elon_vc_podcast_file)\n",
    "all_pairs.extend(pairs_5)\n",
    "\n",
    "# Document 6: Elon Trump Transcript\n",
    "raw_blocks_6 = load_elon_trump_transcript(elon_trump_file)\n",
    "pairs_6 = process_document(raw_blocks_6, elon_trump_file, conversation_type=\"trump\")\n",
    "all_pairs.extend(pairs_6)\n",
    "\n",
    "# Document 7: Lara Trump Interview\n",
    "raw_blocks_7 = load_speaker_transcript(lara_trump_file)\n",
    "pairs_7 = process_document(raw_blocks_7, lara_trump_file, conversation_type=\"lara_trump\")\n",
    "all_pairs.extend(pairs_7)\n",
    "\n",
    "# Document 8: Don Lemon Interview\n",
    "raw_blocks_8 = load_speaker_transcript(don_lemon_file)\n",
    "pairs_8 = process_document(raw_blocks_8, don_lemon_file, conversation_type=\"don_lemon\")\n",
    "all_pairs.extend(pairs_8)\n",
    "\n",
    "# Document 9: 10X Every 6 Months Interview\n",
    "raw_blocks_9 = load_speaker_transcript(ten_x_file)\n",
    "pairs_9 = process_document(raw_blocks_9, ten_x_file, conversation_type=\"ten_x\")\n",
    "all_pairs.extend(pairs_9)\n",
    "\n",
    "# Document 10: CPAC 2025 Interview (reversed speaker mapping)\n",
    "raw_blocks_10 = load_speaker_transcript_reversed(cpac_file)\n",
    "pairs_10 = process_document(raw_blocks_10, cpac_file, conversation_type=\"cpac\")\n",
    "all_pairs.extend(pairs_10)\n",
    "\n",
    "# Document 11: Ben Shapiro Interview\n",
    "raw_blocks_11 = load_speaker_transcript(ben_shapiro_file)\n",
    "pairs_11 = process_document(raw_blocks_11, ben_shapiro_file, conversation_type=\"ben_shapiro\")\n",
    "all_pairs.extend(pairs_11)\n",
    "\n",
    "# Document 12: X Takeover 2025 Interview\n",
    "raw_blocks_12 = load_speaker_transcript(x_takeover_file)\n",
    "pairs_12 = process_document(raw_blocks_12, x_takeover_file, conversation_type=\"x_takeover\")\n",
    "all_pairs.extend(pairs_12)\n",
    "\n",
    "# Document 13: DOGE/Optimus Interview (multiple interviewers)\n",
    "raw_blocks_13 = load_speaker_transcript(doge_optimus_file)\n",
    "pairs_13 = process_document(raw_blocks_13, doge_optimus_file, conversation_type=\"doge_optimus\")\n",
    "all_pairs.extend(pairs_13)\n",
    "\n",
    "# Document 14: Tesla/Politics Interview (reversed speaker mapping)\n",
    "raw_blocks_14 = load_speaker_transcript_reversed(tesla_politics_file)\n",
    "pairs_14 = process_document(raw_blocks_14, tesla_politics_file, conversation_type=\"tesla_politics\")\n",
    "all_pairs.extend(pairs_14)\n",
    "\n",
    "# Document 15: Verdict Interview (reversed speaker mapping, multiple interviewers)\n",
    "raw_blocks_15 = load_speaker_transcript_reversed(verdict_file)\n",
    "pairs_15 = process_document(raw_blocks_15, verdict_file, conversation_type=\"verdict\")\n",
    "all_pairs.extend(pairs_15)\n",
    "\n",
    "# Document 16: Grok 4 Introduction (multiple interviewers)\n",
    "raw_blocks_16 = load_speaker_transcript(grok_4_file)\n",
    "pairs_16 = process_document(raw_blocks_16, grok_4_file, conversation_type=\"grok_4\")\n",
    "all_pairs.extend(pairs_16)\n",
    "\n",
    "# Document 17: Ben Shapiro Interview 2\n",
    "raw_blocks_17 = load_speaker_transcript(ben_shapiro_2_file)\n",
    "pairs_17 = process_document(raw_blocks_17, ben_shapiro_2_file, conversation_type=\"ben_shapiro_2\")\n",
    "all_pairs.extend(pairs_17)\n",
    "\n",
    "# Document 18: TED2022 Interview\n",
    "raw_blocks_18 = load_speaker_transcript(ted_2022_file)\n",
    "pairs_18 = process_document(raw_blocks_18, ted_2022_file, conversation_type=\"ted_2022\")\n",
    "all_pairs.extend(pairs_18)\n",
    "\n",
    "# Document 19: Rishi Sunak Interview\n",
    "raw_blocks_19 = load_speaker_transcript(rishi_sunak_file)\n",
    "pairs_19 = process_document(raw_blocks_19, rishi_sunak_file, conversation_type=\"rishi_sunak\")\n",
    "all_pairs.extend(pairs_19)\n",
    "\n",
    "# Document 20: Digital Superintelligence Interview\n",
    "raw_blocks_20 = load_speaker_transcript(superintelligence_file)\n",
    "pairs_20 = process_document(raw_blocks_20, superintelligence_file, conversation_type=\"superintelligence\")\n",
    "all_pairs.extend(pairs_20)\n",
    "\n",
    "# Document 21: Trump Interview 2\n",
    "raw_blocks_21 = load_speaker_transcript(trump_2_file)\n",
    "pairs_21 = process_document(raw_blocks_21, trump_2_file, conversation_type=\"trump_2\")\n",
    "all_pairs.extend(pairs_21)\n",
    "\n",
    "# Document 22: Trump DOGE Interview (reversed speaker mapping)\n",
    "raw_blocks_22 = load_speaker_transcript_reversed(trump_doge_file)\n",
    "pairs_22 = process_document(raw_blocks_22, trump_doge_file, conversation_type=\"trump_doge\")\n",
    "all_pairs.extend(pairs_22)\n",
    "\n",
    "# Document 23: Tucker Carlson Interview (reversed speaker mapping)\n",
    "raw_blocks_23 = load_speaker_transcript_reversed(tucker_carlson_file)\n",
    "pairs_23 = process_document(raw_blocks_23, tucker_carlson_file, conversation_type=\"tucker_carlson\")\n",
    "all_pairs.extend(pairs_23)\n",
    "\n",
    "# ----------------------------\n",
    "# Apply identity injection\n",
    "# ----------------------------\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"Applying identity injection ({identity_injection_rate*100:.0f}% rate)...\")\n",
    "print(\"=\" * 60)\n",
    "injected_count = 0\n",
    "\n",
    "for pair in all_pairs:\n",
    "    if random.random() < identity_injection_rate:\n",
    "        pair[\"instruction\"] = inject_identity_naturally(pair[\"instruction\"])\n",
    "        injected_count += 1\n",
    "\n",
    "print(f\"✓ Applied to {injected_count}/{len(all_pairs)} pairs\")\n",
    "\n",
    "# ----------------------------\n",
    "# Save\n",
    "# ----------------------------\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(all_pairs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Dataset Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total training pairs: {len(all_pairs)}\")\n",
    "print(f\"System message: '{identity_system_message}'\")\n",
    "print(f\"Identity injection rate: {identity_injection_rate*100:.0f}%\")\n",
    "print(f\"Context window: up to {max_context_turns} previous turns\")\n",
    "print(f\"✓ Saved to: {output_file}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ----------------------------\n",
    "# Sample verification\n",
    "# ----------------------------\n",
    "if all_pairs:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Sample Training Pair\")\n",
    "    print(\"=\" * 60)\n",
    "    sample = all_pairs[0]\n",
    "    context_turns = len([m for m in sample['instruction'] if m['role'] != 'system'])\n",
    "    print(f\"Context turns: {context_turns}\")\n",
    "    print(f\"Response length: {len(sample['response'])} chars\")\n",
    "    print(\"\\nFull sample:\")\n",
    "    print(json.dumps(sample, indent=2)[:800] + \"...\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
